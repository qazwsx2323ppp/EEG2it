# configs/ds003825_triplet_config.yaml
#
# 用 ds003825 (THINGS RSVP EEG, BIDS) 做三元组训练的示例配置：
# - eeg_path 指向 BIDS 根目录（包含 dataset_description.json）
# - 由于 ds003825 在 OpenNeuro 里通常不包含 stimuli/ 图片，推荐先用“概念级”向量：
#     utils/ds003825_embed_concepts.py 生成 [1854, 512] 的 text 向量，并可选择 image 向量= text 向量

defaults:
  - _self_
  - override hydra/launcher: slurm

wandb:
  project: "EEG_Decoupling"
  entity: null
  name: "eeg_triplet_train_ds003825"

data:
  root: ${hydra:runtime.cwd}
  split_index: 0
  num_concepts: 1854

  # 关键：指向 BIDS 根目录（可用环境变量覆盖，避免换机器就改 yaml）
  backend: "ds003825"
  eeg_path: ${oc.env:DS003825_ROOT,${data.root}/data/ds003825}

  # 概念级向量（objectnumber 0..1853），推荐先用 text-only 方案：
  #  - out-text 生成到 data/ds003825_concept_text.npy
  #  - out-image 生成到 data/ds003825_concept_image.npy（方案一：用不同 prompt 得到“image-like”向量）
  image_vec_path: ${data.root}/data/ds003825_concept_image.npy
  text_vec_path: ${data.root}/data/ds003825_concept_text.npy

  # 可选：你也可以提供 splits_path（splits['splits'][split_index][train/val/test]），否则默认按 subject 划分
  splits_path: ""

  # ds003825 专用开关
  target_channels: 128
  include_teststim: false
  include_targets: false
  trial_stride: 10       # 每隔 N 条取 1 条；数据量很大，建议先从 10/20 开始
  drop_exclude_flagged: true
  unique_concepts_per_batch: true
  return_concept_id: true
  zscore: true
  zscore_eps: 1e-6
  # subjects: "sub-02,sub-03"   # 可选：只用部分被试
  # exclude_subjects: "sub-01,sub-06,sub-18,sub-23"

training:
  epochs: 50
  batch_size: 64
  learning_rate: 0.0001
  num_workers: 4
  device: "cuda"
  pin_memory: true
  persistent_workers: true
  print_epoch_losses: true
  sanity_check: true
  early_stopping: true
  # 仅做 text 语义对齐（不使用 image 分支）；此时会自动 alpha=0 且跳过 image retrieval 指标
  text_only: true
  # 以 Top-k 指标作为「保存 best / 早停」的主导指标
  selection_metric: "val/txt_top1"
  selection_mode: "max"
  use_wandb: false
  k_values: [1, 5, 10]

  # 大数据集训练建议：限制每个 epoch 的迭代步数（想跑全量就设为 0 或删除）
  max_steps_per_epoch: 500
  max_val_steps: 200
  grad_accum_steps: 1
  log_every: 50
  warmup_ratio: 0.1

  distributed:
    enabled: true
    backend: "nccl"
    find_unused_parameters: true
  patience: 5
  # Top-1 是 [0,1] 的小数；min_delta 设太大会导致「Top-1 变好但不保存」
  min_delta: 0.0001
  weight_decay: 0.1
  alpha: 0.5            # 方案一：image_vec/text_vec 来自不同 prompt，可用双头共同训练
  temperature: 0.2

model:
  model_name: 'eeg_moe'
  pretrained_path: ${oc.env:DREAMDIFF_CKPT,${data.root}/temp/checkpoint.pth}
  n_linear_layers: 1
  channel_merge: 'linear'
  n_heads: 8
  embedding_dim: 512
  n_channels: 128
  n_samples: 512
  encoder_name: 'braindecode_shallow'

  moe_config:
    router_type: "global_channel_attention"

  n_filters_time: 20
  filter_time_length: 25
  n_filters_spat: 20
  pool_time_length: 75
  pool_time_stride: 15
  drop_prob: 0.6

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
