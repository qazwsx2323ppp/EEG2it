import json
import os
import pandas as pd
import subprocess
import sys
import wandb
import glob

# ==========================================
# 1. é…ç½®ä½ çš„è·¯å¾„ (è¯·æŒ‡å‘åŒ…å« .wandb æ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼Œè€Œä¸æ˜¯æ–‡ä»¶æœ¬èº«)
# ä¾‹å¦‚: D:\CODE\EEG\EEG2it\temp\wandb
WANDB_RUN_DIR = r"D:\CODE\EEG\EEG2it\temp\wandb"
# ==========================================

print(f"ğŸ“Œ Wandb ç‰ˆæœ¬ï¼š{wandb.__version__}")
print(f"ğŸ“Œ ç›®æ ‡æ–‡ä»¶å¤¹ï¼š{WANDB_RUN_DIR}")

# è‡ªåŠ¨å¯»æ‰¾ .wandb æ–‡ä»¶
wandb_files = glob.glob(os.path.join(WANDB_RUN_DIR, "*.wandb"))
if not wandb_files:
    print("âŒ é”™è¯¯ï¼šåœ¨è¯¥ç›®å½•ä¸‹æ²¡æ‰¾åˆ°ä»»ä½• .wandb æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")
    sys.exit(1)

target_file = wandb_files[0]
print(f"ğŸ“Œ é”å®šç›®æ ‡æ–‡ä»¶ï¼š{target_file}")

# è®¾ç½®ç¦»çº¿ç¯å¢ƒå˜é‡
env = os.environ.copy()
env["WANDB_MODE"] = "offline"
env["WANDB_SILENT"] = "true"

print("\nğŸ”§ æ­£åœ¨å°è¯•è§£ææ•°æ® (wandb sync)...")
# ä½¿ç”¨ sync å‘½ä»¤å°†æ•°æ®å¯¼å‡ºåˆ°å½“å‰ç›®å½•
command = [sys.executable, "-m", "wandb", "sync", "--include-offline", WANDB_RUN_DIR]

try:
    result = subprocess.run(command, env=env, capture_output=True, text=True, encoding="utf-8")
    if result.returncode != 0:
        print("âš ï¸ sync å‘½ä»¤è¿”å›äº†é”™è¯¯ä»£ç ï¼Œä½†è¿™å¯èƒ½ä¸å½±å“æ•°æ®ç”Ÿæˆã€‚")
        print(f"é”™è¯¯è¾“å‡º: {result.stderr}")
except Exception as e:
    print(f"âŒ æ‰§è¡Œ sync å‘½ä»¤æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

print("\nâœ… åŒæ­¥å°è¯•ç»“æŸï¼Œå¼€å§‹å¯»æ‰¾ç”Ÿæˆçš„ CSV æ•°æ®...")

# WandB sync é€šå¸¸ä¼šåœ¨ WANDB_RUN_DIR æˆ–è€…å½“å‰ç›®å½•ä¸‹ç”Ÿæˆ metrics.csv
# æˆ‘ä»¬éå†æŸ¥æ‰¾ä¸€ä¸‹
search_paths = [
    os.path.join(WANDB_RUN_DIR, "metrics.csv"),
    "metrics.csv",  # å½“å‰è„šæœ¬ç›®å½•
]
# æœ‰æ—¶å€™ wandb ä¼šç”Ÿæˆåœ¨å­æ–‡ä»¶å¤¹é‡Œï¼Œé€’å½’æ‰¾ä¸€ä¸‹
for root, dirs, files in os.walk(WANDB_RUN_DIR):
    if "metrics.csv" in files:
        search_paths.append(os.path.join(root, "metrics.csv"))

metrics_df = None
found_csv = None

for csv_path in search_paths:
    if os.path.exists(csv_path) and os.path.getsize(csv_path) > 0:
        print(f"ğŸ‰ æ‰¾åˆ°äº†æŒ‡æ ‡æ–‡ä»¶ï¼š{csv_path}")
        try:
            metrics_df = pd.read_csv(csv_path)
            found_csv = csv_path
            break
        except Exception as e:
            print(f"âŒ è¯»å– {csv_path} å¤±è´¥: {e}")

# ==========================================
# æ ¸å¿ƒä¿®å¤ï¼šå¢åŠ ç©ºå€¼æ£€æŸ¥ï¼Œé˜²æ­¢ AttributeError
# ==========================================
if metrics_df is not None:
    # è¿‡æ»¤åˆ—å
    cols = metrics_df.columns.tolist()
    useful_cols = [c for c in cols if any(k in c for k in ["epoch", "loss", "sim", "acc", "lr"])]
    
    # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šçš„åˆ—ï¼Œå°±ä¿ç•™æ‰€æœ‰åˆ—
    if not useful_cols:
        useful_cols = cols
        
    final_df = metrics_df[useful_cols].dropna(how="all")
    
    # ä¿å­˜ç»“æœ
    output_file = "wandb_metrics_fixed.json"
    final_df.to_json(output_file, orient="records", indent=2, force_ascii=False)
    
    print(f"\nâœ…âœ…âœ… æˆåŠŸï¼æ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")
    print(f"ğŸ“Š åŒ…å«å­—æ®µ: {useful_cols}")
    print(f"ğŸ“„ æ€»è¡Œæ•°: {len(final_df)}")
else:
    print("\nâŒâŒâŒ å¤±è´¥ï¼šæœªèƒ½ç”Ÿæˆæˆ–è¯»å–åˆ° metrics.csvã€‚")
    print("å¯èƒ½åŸå› ï¼š")
    print("1. æ–‡ä»¶æƒé™ä¾ç„¶è¢«é”ï¼ˆè¯·æ‰§è¡Œç¬¬ä¸€æ­¥ taskkillï¼‰")
    print("2. .wandb æ–‡ä»¶æœ¬èº«å·²æŸåï¼ˆæ— æ³•è§£æï¼‰")
    print("3. æ–‡ä»¶åªè¯»å±æ€§æœªå–æ¶ˆ")