import sys
from pathlib import Path
project_root = Path(__file__).parent.parent 
sys.path.append(str(project_root))
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
from omegaconf import OmegaConf
import seaborn as sns # å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œå¯ä»¥ä½¿ç”¨ pip install seabornï¼Œä¼šè®©å›¾è¡¨æ›´å¥½çœ‹

# å¼•å…¥ä½ çš„æ¨¡å—
from models.clip_models import SpatialMoEEncoder
from dataset import TripletDataset
from utils.loss_methods import InfoNCE

# === é…ç½®åŒºåŸŸ ===
CONFIG_PATH = "configs/triplet_config.yaml"
# æ›¿æ¢ä¸ºä½ åˆšåˆšè®­ç»ƒå‡ºçš„æœ€ä½³æƒé‡è·¯å¾„
MODEL_PATH = "temp/best_12.8_change.pth"  
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
OUTPUT_DIR = "results/ablation_study" # ç»“æœä¿å­˜ç›®å½•
# ================

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

def run_validation(model, loader, loss_fn, ablation=None, desc="Validating"):
    model.eval()
    total_img_loss = 0.0
    total_txt_loss = 0.0
    
    # ç”¨äºå­˜å‚¨æƒé‡åˆ†å¸ƒ
    all_vis_weights = []
    all_sem_weights = []

    with torch.no_grad():
        for batch in tqdm(loader, desc=desc):
            eeg, img_vecs, txt_vecs = batch
            eeg = eeg.to(DEVICE)
            img_vecs = img_vecs.to(DEVICE)
            txt_vecs = txt_vecs.to(DEVICE)

            # ä¼ å…¥ ablation å‚æ•°
            eeg_img, eeg_txt, weights = model(eeg, ablation=ablation)

            # è®¡ç®— Loss
            loss_i = loss_fn(eeg_img, img_vecs)
            loss_t = loss_fn(eeg_txt, txt_vecs)

            total_img_loss += loss_i.item()
            total_txt_loss += loss_t.item()
            
            # æ”¶é›†æƒé‡ (å– batch å¹³å‡æˆ–æ‰€æœ‰æ ·æœ¬)
            if weights:
                # æ³¨æ„ï¼šæ ¹æ®ä½ çš„æ¨¡å‹è¿”å›ï¼Œweights å¯èƒ½åœ¨ GPU ä¸Šï¼Œéœ€è¦è½¬åˆ° CPU
                if 'w_vis_img' in weights:
                    all_vis_weights.extend(weights['w_vis_img'].cpu().numpy().flatten())
                if 'w_sem_txt' in weights:
                    all_sem_weights.extend(weights['w_sem_txt'].cpu().numpy().flatten())

    avg_img_loss = total_img_loss / len(loader)
    avg_txt_loss = total_txt_loss / len(loader)
    
    return avg_img_loss, avg_txt_loss, np.array(all_vis_weights), np.array(all_sem_weights)

def plot_results(results_df):
    """ç»˜åˆ¶è®ºæ–‡å¯ç”¨çš„ Loss å¯¹æ¯”å›¾"""
    plt.figure(figsize=(10, 6))
    
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥ä¾¿ç»˜å›¾ (Melt)
    df_melted = results_df.melt(id_vars=["Experiment"], 
                                value_vars=["Image Loss", "Text Loss"], 
                                var_name="Modality", 
                                value_name="Loss")
    
    # è®¾ç½® Seaborn é£æ ¼ï¼ˆå¯é€‰ï¼‰
    try:
        sns.set_theme(style="whitegrid")
        ax = sns.barplot(data=df_melted, x="Experiment", y="Loss", hue="Modality", palette="viridis")
    except NameError:
        # å¦‚æœæ²¡æœ‰ seabornï¼Œä½¿ç”¨ matplotlib æ ‡å‡†ç»˜å›¾
        df_melted.pivot(index='Experiment', columns='Modality', values='Loss').plot(kind='bar')
        plt.grid(True, axis='y', linestyle='--', alpha=0.7)
    
    plt.title("Impact of Expert Ablation on Retrieval Loss", fontsize=14)
    plt.ylabel("Loss (Lower is Better)", fontsize=12)
    plt.xlabel("Ablation Condition", fontsize=12)
    plt.xticks(rotation=0)
    plt.legend(title="Task Modality")
    
    save_path = os.path.join(OUTPUT_DIR, "ablation_comparison.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    print(f"ğŸ“Š Loss å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º: {save_path}")
    plt.close()

def plot_weights(vis_w, sem_w):
    """ç»˜åˆ¶æƒé‡åˆ†å¸ƒç›´æ–¹å›¾"""
    plt.figure(figsize=(10, 5))
    plt.hist(vis_w, bins=50, alpha=0.6, color='blue', label='Visual Expert Weights (w_vis)', density=True)
    plt.hist(sem_w, bins=50, alpha=0.6, color='orange', label='Semantic Expert Weights (w_sem)', density=True)
    
    plt.title("Distribution of Router Weights (Validation Set)", fontsize=14)
    plt.xlabel("Gate Value (0.0 - 1.0)", fontsize=12)
    plt.ylabel("Density", fontsize=12)
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.3)
    
    save_path = os.path.join(OUTPUT_DIR, "router_distribution.png")
    plt.savefig(save_path, dpi=300)
    print(f"ğŸ“Š æƒé‡åˆ†å¸ƒå›¾å·²ä¿å­˜ä¸º: {save_path}")
    plt.close()

def main():
    # 1. åŠ è½½é…ç½®
    cfg = OmegaConf.load(CONFIG_PATH)
    cfg.data.root = os.getcwd()  # è·å–å½“å‰å·¥ä½œç›®å½•

    # 2. å‡†å¤‡æ•°æ®
    val_dataset = TripletDataset(cfg.data, mode='val', split_index=0)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    # 3. åŠ è½½æ¨¡å‹
    print(f"Loading model from {MODEL_PATH}...")
    try:
        model = SpatialMoEEncoder(
            n_channels=128,
            n_samples=512, 
            embedding_dim=512
        ).to(DEVICE)
    except TypeError:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½ çš„æ¨¡å‹å®šä¹‰è¿˜éœ€è¦ indices å‚æ•°
        print("Model requires indices args, passing empty lists...")
        model = SpatialMoEEncoder(
            n_channels=128, n_samples=512,
            visual_indices=[], semantic_indices=[],
            embedding_dim=512
        ).to(DEVICE)
    
    # åŠ è½½æƒé‡
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state_dict, strict=False)
    
    loss_fn = InfoNCE(initial_temperature=0.07).to(DEVICE)

    # === å®šä¹‰å®éªŒåˆ—è¡¨ ===
    experiments = [
        ("Baseline (Full)", None),
        ("Kill Visual", "kill_visual"),
        ("Kill Semantic", "kill_semantic")
    ]

    results_data = []
    base_img_loss = 0
    base_txt_loss = 0

    # 4. å¾ªç¯è¿è¡Œå®éªŒ
    for exp_name, ablation_mode in experiments:
        print(f"\n>>> Running Experiment: {exp_name} ...")
        img_loss, txt_loss, vis_w, sem_w = run_validation(
            model, val_loader, loss_fn, ablation=ablation_mode, desc=exp_name
        )

        # å¦‚æœæ˜¯ Baselineï¼Œä¿å­˜æƒé‡åˆ†å¸ƒå›¾
        if ablation_mode is None:
            base_img_loss = img_loss
            base_txt_loss = txt_loss
            plot_weights(vis_w, sem_w)
        
        # è®¡ç®— Delta (å˜åŒ–é‡)
        delta_img = img_loss - base_img_loss
        delta_txt = txt_loss - base_txt_loss
        
        print(f"   Image Loss: {img_loss:.4f} (Delta: {delta_img:+.4f})")
        print(f"   Text Loss:  {txt_loss:.4f} (Delta: {delta_txt:+.4f})")
        
        # è®°å½•æ•°æ®
        results_data.append({
            "Experiment": exp_name,
            "Image Loss": img_loss,
            "Text Loss": txt_loss,
            "Image Loss Delta": delta_img,
            "Text Loss Delta": delta_txt
        })

    # 5. ä¿å­˜æ•°æ®åˆ° CSV
    df = pd.DataFrame(results_data)
    csv_path = os.path.join(OUTPUT_DIR, "ablation_results.csv")
    df.to_csv(csv_path, index=False, float_format='%.4f')
    print(f"\nâœ… å®éªŒæ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
    print(df)

    # 6. ç»˜åˆ¶ Loss å¯¹æ¯”å›¾
    plot_results(df)

    # === ç»“è®ºåˆ†æ (è‡ªåŠ¨å†™å…¥æ–‡æœ¬æ–‡ä»¶) ===
    analysis_path = os.path.join(OUTPUT_DIR, "analysis_report.txt")
    with open(analysis_path, "w", encoding="utf-8") as f:
        f.write("=== MoE Ablation Study Analysis ===\n\n")
        f.write(df.to_string(index=False))
        f.write("\n\n")
        
        # ç®€å•çš„è‡ªåŠ¨ç»“è®º
        baseline = df[df['Experiment'] == "Baseline (Full)"].iloc[0]
        kill_vis = df[df['Experiment'] == "Kill Visual"].iloc[0]
        kill_sem = df[df['Experiment'] == "Kill Semantic"].iloc[0]

        if kill_vis['Image Loss'] > baseline['Image Loss'] + 0.05:
            msg = "âœ… [éªŒè¯æˆåŠŸ] åˆ‡é™¤è§†è§‰ä¸“å®¶å¯¼è‡´ Image Loss æ˜¾è‘—ä¸Šå‡ï¼Œè¯æ˜è§†è§‰ä¸“å®¶ä¸»è¦è´Ÿè´£è§†è§‰ä»»åŠ¡ã€‚\n"
            print(msg.strip())
            f.write(msg)
        
        if kill_sem['Text Loss'] > baseline['Text Loss'] + 0.05:
            msg = "âœ… [éªŒè¯æˆåŠŸ] åˆ‡é™¤è¯­ä¹‰ä¸“å®¶å¯¼è‡´ Text Loss æ˜¾è‘—ä¸Šå‡ï¼Œè¯æ˜è¯­ä¹‰ä¸“å®¶ä¸»è¦è´Ÿè´£æ–‡æœ¬ä»»åŠ¡ã€‚\n"
            print(msg.strip())
            f.write(msg)

    print(f"ğŸ“„ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {analysis_path}")

if __name__ == "__main__":
    main()